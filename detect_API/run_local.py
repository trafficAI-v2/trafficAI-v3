#!/usr/bin/env python3
"""
æœ¬åœ°é‹è¡Œç‰ˆæœ¬çš„å®‰å…¨å¸½æª¢æ¸¬ç³»çµ±
ç›´æ¥åœ¨ macOS ä¸»æ©Ÿä¸Šé‹è¡Œï¼Œå¯å®Œç¾å­˜å–æœ¬åœ°æ”å½±æ©Ÿ
"""

import os
import sys
import cv2
import time
import requests
import psycopg2 
import threading
import logging
import queue
from datetime import datetime
from ultralytics import YOLO
from dotenv import load_dotenv
from flask import Flask, jsonify, request, Response
from flask_cors import CORS

# è¨­å®šç’°å¢ƒè®Šæ•¸æª”æ¡ˆè·¯å¾‘
env_path = os.path.join(os.path.dirname(__file__), '..', '.env')
load_dotenv(env_path)

# ==================== 1. åˆå§‹åŒ–èˆ‡è¨­å®š ====================
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')
log = logging.getLogger('werkzeug')
log.setLevel(logging.ERROR)
app = Flask(__name__)
CORS(app, origins=['http://localhost:8080'], supports_credentials=True)

# æœ¬åœ°é‹è¡Œæ¨¡å¼çš„è·¯å¾‘è¨­å®š
MODEL_PATH = os.path.join(os.path.dirname(__file__), 'halbest.pt')
DATABASE_URL = os.getenv('DATABASE_URL')
LPR_API_URL = "http://localhost:3001/recognize_plate"  # æœ¬åœ°æ¨¡å¼ä½¿ç”¨ localhost

print(f"ğŸ”§ æœ¬åœ°é‹è¡Œæ¨¡å¼é…ç½®:")
print(f"   æ¨¡å‹è·¯å¾‘: {MODEL_PATH}")
print(f"   è³‡æ–™åº«: {'å·²é…ç½®' if DATABASE_URL else 'æœªé…ç½®'}")
print(f"   è»Šç‰ŒAPI: {LPR_API_URL}")

# å…¨åŸŸè®Šæ•¸ç®¡ç†
global_cap = None
no_helmet_model = None
stop_detection_flag = True

# åŸ·è¡Œç·’å®‰å…¨çš„ä½‡åˆ—å’Œé–
frame_queue = queue.Queue(maxsize=2)
producer_thread = None
logic_thread = None
inference_thread = None

# å…±äº«çš„æœ€æ–°çµæœ (å—é–ä¿è­·)
latest_frame = None
latest_results = None
data_lock = threading.Lock()

# å¸¸æ•¸è¨­å®š
NO_HELMET_CLASS_NAME = 'no-helmet'
CONFIDENCE_THRESHOLD = 0.65
VISUAL_CONFIDENCE = 0.4
SCREENSHOT_PATH = "successful_detections"
EXPAND_DOWN_FACTOR = 5.0
EXPAND_SIDES_FACTOR = 1.5

if not os.path.exists(SCREENSHOT_PATH):
    os.makedirs(SCREENSHOT_PATH)

# ==================== 2. è¼”åŠ©å‡½å¼ ====================
def call_lpr_api(image_data):
    try:
        _, img_encoded = cv2.imencode('.jpg', image_data)
        files = {'file': ('violation.jpg', img_encoded.tobytes(), 'image/jpeg')}
        response = requests.post(LPR_API_URL, files=files, timeout=10)
        
        if response.status_code == 200:
            result = response.json()
            if 'data' in result and result['data'] is not None:
                return result['data']
        elif response.status_code == 404:
            return None
        else:
            logging.error(f"API è«‹æ±‚éŒ¯èª¤ï¼Œç‹€æ…‹ç¢¼: {response.status_code}, å›æ‡‰: {response.text}")
            return None
    except requests.exceptions.RequestException as e:
        logging.error(f"å‘¼å« API æ™‚ç™¼ç”Ÿç¶²è·¯éŒ¯èª¤: {e}")
        return None

def save_to_database(owner_info, image_path):
    if not DATABASE_URL:
        logging.warning("è³‡æ–™åº«æœªé…ç½®ï¼Œè·³éè³‡æ–™å„²å­˜")
        return
        
    sql = """
        INSERT INTO violations (
            license_plate, owner_name, owner_phone, owner_email,
            owner_address, violation_type, violation_address,
            image_path, timestamp, fine
        ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
    """
    conn = None 
    try:
        with psycopg2.connect(DATABASE_URL) as conn:
            with conn.cursor() as cur:
                cur.execute(sql, (
                    owner_info.get('license_plate_number', 'N/A'),
                    owner_info.get('full_name', 'N/A'),
                    owner_info.get('phone_number', 'N/A'),
                    owner_info.get('email', 'N/A'),
                    owner_info.get('address', 'N/A'),
                    'æœªæˆ´å®‰å…¨å¸½',
                    'é«˜é›„å¸‚ç‡•å·¢å€å®‰æ‹›é‡Œå®‰æ—è·¯112è™Ÿ',
                    image_path,
                    datetime.now(),
                    800
                ))
    except (Exception, psycopg2.DatabaseError) as error:
        logging.error(f"è³‡æ–™åº«å¯«å…¥éŒ¯èª¤: {error}")
    finally:
        if conn is not None:
            conn.close()

# ==================== 3. æ ¸å¿ƒåµæ¸¬èˆ‡ä¸²æµé‚è¼¯ ====================
def frame_producer():
    global stop_detection_flag, global_cap, frame_queue
    logging.info("ğŸ“¹ å½±åƒç”Ÿç”¢è€…åŸ·è¡Œç·’å·²å•Ÿå‹• (æœ¬åœ°æ¨¡å¼)")
    while not stop_detection_flag:
        if not (global_cap and global_cap.isOpened()):
            time.sleep(0.1)
            continue
        ret, frame = global_cap.read()
        if not ret:
            logging.warning("è®€å–å½±åƒå¹€å¤±æ•—ï¼Œä¾†æºå¯èƒ½å·²çµæŸã€‚")
            time.sleep(0.5)
            continue
        if not frame_queue.full():
            frame_queue.put(frame)
    logging.info("ğŸ“¹ å½±åƒç”Ÿç”¢è€…åŸ·è¡Œç·’å·²çµæŸ")

def perform_inference():
    global stop_detection_flag, no_helmet_model, frame_queue, latest_frame, latest_results, data_lock
    logging.info("ğŸ§  æ¨¡å‹æ¨ç†åŸ·è¡Œç·’å·²å•Ÿå‹• (æœ¬åœ°æ¨¡å¼)")
    while not stop_detection_flag:
        try:
            frame = frame_queue.get(timeout=1)
            results = no_helmet_model(frame, conf=VISUAL_CONFIDENCE, verbose=False)
            with data_lock:
                latest_frame = frame
                latest_results = results[0]
        except queue.Empty:
            continue
    logging.info("ğŸ§  æ¨¡å‹æ¨ç†åŸ·è¡Œç·’å·²çµæŸ")

def run_detection_logic():
    global stop_detection_flag, latest_results, data_lock, latest_frame
    last_successful_detection_time = 0
    violation_cooldown = 2.0
    logging.info("ğŸ” èƒŒæ™¯åµæ¸¬é‚è¼¯åŸ·è¡Œç·’å·²å•Ÿå‹• (æœ¬åœ°æ¨¡å¼)")
    
    while not stop_detection_flag:
        time.sleep(0.1)
        with data_lock:
            if latest_frame is None or latest_results is None:
                continue
            local_frame_copy = latest_frame.copy()
            local_results = latest_results
        
        current_time = time.time()
        if current_time - last_successful_detection_time > violation_cooldown:
            frame_height, frame_width, _ = local_frame_copy.shape
            for box in local_results.boxes:
                if box.conf[0] > CONFIDENCE_THRESHOLD:
                    class_name = no_helmet_model.names[int(box.cls[0])]
                    if class_name.lower() == NO_HELMET_CLASS_NAME.lower():
                        x1, y1, x2, y2 = map(int, box.xyxy[0])
                        box_width = x2 - x1
                        box_height = y2 - y1
                        new_x1 = max(0, x1 - int(box_width * EXPAND_SIDES_FACTOR))
                        new_y1 = max(0, y1)
                        new_x2 = min(frame_width, x2 + int(box_width * EXPAND_SIDES_FACTOR))
                        new_y2 = min(frame_height, y2 + int(box_height * EXPAND_DOWN_FACTOR))
                        crop_img = local_frame_copy[new_y1:new_y2, new_x1:new_x2]
                        
                        if crop_img.size > 0:
                            owner_info = call_lpr_api(crop_img)
                            if owner_info:
                                ts_str = time.strftime("%Y%m%d_%H%M%S")
                                filename = os.path.join(SCREENSHOT_PATH, f"success_{ts_str}.jpg")
                                cv2.imwrite(filename, crop_img)
                                save_to_database(owner_info, filename)
                                last_successful_detection_time = time.time()
                                plate = owner_info.get('license_plate_number', 'N/A')
                                logging.info(f"âœ… æˆåŠŸåµæ¸¬åˆ°é•è¦ (è»Šç‰Œ: {plate})ï¼Œè³‡æ–™å·²å¯«å…¥è³‡æ–™åº«")
                                break 
    logging.info("ğŸ” èƒŒæ™¯åµæ¸¬é‚è¼¯åŸ·è¡Œç·’å·²çµæŸ")

def generate_frames():
    global stop_detection_flag, data_lock, latest_frame, latest_results
    while not stop_detection_flag:
        time.sleep(1/30)
        with data_lock:
            if latest_frame is None or latest_results is None:
                continue
            frame_to_show = latest_frame.copy()
            results_to_show = latest_results

        for box in results_to_show.boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            conf = box.conf[0]
            class_name = no_helmet_model.names[int(box.cls[0])]
            color = (0, 0, 255) if class_name.lower() == NO_HELMET_CLASS_NAME.lower() else (0, 255, 0)
            cv2.rectangle(frame_to_show, (x1, y1), (x2, y2), color, 2)
            label = f'{class_name} {conf:.2f}'
            cv2.putText(frame_to_show, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

        (flag, encodedImage) = cv2.imencode(".jpg", frame_to_show)
        if not flag:
            continue
        yield(b'--frame\r\n' b'Content-Type: image/jpeg\r\n\r\n' + bytearray(encodedImage) + b'\r\n')

# ==================== 4. Flask API ç«¯é» ====================
@app.route('/video_feed')
def video_feed():
    return Response(generate_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')

@app.route('/start_detection', methods=['POST'])
def start_detection():
    global global_cap, no_helmet_model, stop_detection_flag, producer_thread, logic_thread, inference_thread
    
    if producer_thread and producer_thread.is_alive():
        return jsonify({"status": "fail", "message": "åµæ¸¬å·²ç¶“åœ¨é‹è¡Œä¸­ã€‚"}), 400

    data = request.get_json()
    video_path = data.get('video_path')
    if not video_path:
        return jsonify({"status": "fail", "message": "è«‹æä¾› 'video_path'ã€‚"}), 400

    # è¼‰å…¥æ¨¡å‹
    if no_helmet_model is None:
        try:
            if not os.path.exists(MODEL_PATH):
                return jsonify({"status": "fail", "message": f"æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨: {MODEL_PATH}"}), 500
            no_helmet_model = YOLO(MODEL_PATH)
            logging.info("âœ… YOLO æ¨¡å‹è¼‰å…¥æˆåŠŸï¼(æœ¬åœ°æ¨¡å¼)")
        except Exception as e:
            return jsonify({"status": "fail", "message": f"æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}"}), 500

    # å˜—è©¦é–‹å•Ÿæ”å½±æ©Ÿ
    try:
        capture_source = int(video_path) if video_path.isdigit() else video_path
        global_cap = cv2.VideoCapture(capture_source)
        
        if not global_cap.isOpened():
            raise IOError(f"ç„¡æ³•é–‹å•Ÿå½±åƒä¾†æº: {video_path}")
            
        # æ¸¬è©¦è®€å–ä¸€å¹€
        ret, test_frame = global_cap.read()
        if not ret:
            global_cap.release()
            raise IOError(f"æ”å½±æ©Ÿ {video_path} å¯ä»¥é–‹å•Ÿä½†ç„¡æ³•è®€å–ç•«é¢")
            
        logging.info(f"âœ… æ”å½±æ©Ÿé€£ç·šæˆåŠŸï¼è§£æåº¦: {test_frame.shape[1]}x{test_frame.shape[0]}")
        
    except Exception as e:
        return jsonify({"status": "fail", "message": str(e)}), 400

    # å•Ÿå‹•åŸ·è¡Œç·’
    stop_detection_flag = False
    producer_thread = threading.Thread(target=frame_producer, daemon=True)
    inference_thread = threading.Thread(target=perform_inference, daemon=True)
    logic_thread = threading.Thread(target=run_detection_logic, daemon=True)
    
    producer_thread.start()
    inference_thread.start()
    logic_thread.start()
    
    logging.info(f"ğŸš€ åµæ¸¬ä»»å‹™é–‹å§‹ï¼Œå½±åƒä¾†æº: '{video_path}' (æœ¬åœ°æ¨¡å¼)")
    return jsonify({"status": "success"})

@app.route('/stop_detection', methods=['POST'])
def stop_detection():
    global global_cap, stop_detection_flag, producer_thread, logic_thread, inference_thread, latest_frame, latest_results

    if not (producer_thread and producer_thread.is_alive()):
        return jsonify({"status": "fail", "message": "åµæ¸¬ä¸¦æœªåœ¨é‹è¡Œä¸­ã€‚"}), 400
    
    logging.info("ğŸ›‘ æ”¶åˆ°åœæ­¢åµæ¸¬çš„è«‹æ±‚...")
    stop_detection_flag = True
    
    if producer_thread: producer_thread.join()
    if inference_thread: inference_thread.join()
    if logic_thread: logic_thread.join()
    
    if global_cap:
        global_cap.release()
        global_cap = None
        
    with frame_queue.mutex: frame_queue.queue.clear()
    with data_lock:
        latest_frame = None
        latest_results = None

    producer_thread, inference_thread, logic_thread = None, None, None
    
    logging.info("âœ… åµæ¸¬å·²å®Œå…¨åœæ­¢ (æœ¬åœ°æ¨¡å¼)")
    return jsonify({"status": "success", "message": "åµæ¸¬å·²åœæ­¢ã€‚"})

@app.route('/status', methods=['GET'])
def get_status():
    if producer_thread and producer_thread.is_alive():
        return jsonify({"status": "running", "message": "åµæ¸¬æ­£åœ¨é‹è¡Œä¸­ (æœ¬åœ°æ¨¡å¼)ã€‚"})
    else:
        return jsonify({"status": "stopped", "message": "åµæ¸¬å·²åœæ­¢ (æœ¬åœ°æ¨¡å¼)ã€‚"})

@app.route('/test_camera', methods=['POST'])
def test_camera():
    """æ¸¬è©¦æ”å½±æ©Ÿé€£ç·šç‹€æ…‹"""
    data = request.get_json()
    video_path = data.get('video_path')
    if not video_path:
        return jsonify({"status": "fail", "message": "è«‹æä¾› 'video_path'ã€‚"}), 400
    
    try:
        capture_source = int(video_path) if video_path.isdigit() else video_path
        test_cap = cv2.VideoCapture(capture_source)
        
        if test_cap.isOpened():
            ret, frame = test_cap.read()
            test_cap.release()
            
            if ret and frame is not None:
                height, width = frame.shape[:2]
                return jsonify({
                    "status": "success", 
                    "message": f"æ”å½±æ©Ÿ {video_path} é€£ç·šæˆåŠŸ (æœ¬åœ°æ¨¡å¼)",
                    "resolution": f"{width}x{height}",
                    "source_type": "æœ¬åœ°æ”å½±æ©Ÿ"
                })
            else:
                return jsonify({
                    "status": "fail", 
                    "message": f"æ”å½±æ©Ÿ {video_path} å¯ä»¥é–‹å•Ÿä½†ç„¡æ³•è®€å–ç•«é¢"
                }), 400
        else:
            test_cap.release()
            return jsonify({
                "status": "fail", 
                "message": f"ç„¡æ³•é€£ç·šåˆ°æ”å½±æ©Ÿ: {video_path}"
            }), 400
            
    except Exception as e:
        return jsonify({"status": "fail", "message": f"æ¸¬è©¦å¤±æ•—: {str(e)}"}), 500

# ==================== 5. å•Ÿå‹•ä¼ºæœå™¨ ====================
if __name__ == "__main__":
    print("ğŸ¬ äº¤é€š AI ç³»çµ± - æœ¬åœ°é‹è¡Œæ¨¡å¼")
    print("=" * 50)
    print("ğŸ“¹ æ”å½±æ©Ÿå­˜å–æ¨¡å¼ï¼šæœ¬åœ°ç›´é€£ (ç¹é Docker é™åˆ¶)")
    print("ğŸŒ API æœå‹™ç«¯å£ï¼š5001")
    print("ğŸ”§ æ¨¡å‹è·¯å¾‘ï¼š", MODEL_PATH)
    print("=" * 50)
    
    # æª¢æŸ¥æ¨¡å‹æª”æ¡ˆ
    if not os.path.exists(MODEL_PATH):
        print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆ {MODEL_PATH}")
        print(f"è«‹ç¢ºä¿ halbest.pt æª”æ¡ˆåœ¨ {os.path.dirname(__file__)} ç›®éŒ„ä¸­")
        sys.exit(1)
    
    # æ¸¬è©¦æ”å½±æ©Ÿ
    print("ğŸ” æ­£åœ¨æ¸¬è©¦æ”å½±æ©Ÿå­˜å–...")
    test_cap = cv2.VideoCapture(0)
    if test_cap.isOpened():
        ret, frame = test_cap.read()
        if ret:
            print(f"âœ… æ”å½±æ©Ÿ 0 å¯ç”¨ï¼Œè§£æåº¦: {frame.shape[1]}x{frame.shape[0]}")
        test_cap.release()
    else:
        print("âš ï¸  æ”å½±æ©Ÿ 0 ç„¡æ³•å­˜å–ï¼Œæ‚¨ä»å¯ä»¥å˜—è©¦å…¶ä»–ç´¢å¼•")
    
    print("\nğŸš€ å•Ÿå‹• Flask ä¼ºæœå™¨...")
    print("ğŸ“± å‰ç«¯è«‹è¨ªå•: http://localhost:8080")
    print("ğŸ”§ API ç«¯é»: http://localhost:5001")
    print("æŒ‰ Ctrl+C åœæ­¢æœå‹™\n")
    
    app.run(host='0.0.0.0', port=5001, debug=True, use_reloader=False)